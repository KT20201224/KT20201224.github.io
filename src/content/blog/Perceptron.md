---
title: 퍼셉트론, Perceptron
pubDate: 2025-10-20
description: 퍼셉트론에 대한 정리
author: KT
tags:
  - DeepLearning
  - Perceptron
---
퍼셉트론은 인공신경망의 가장 기본이 되는 단일 뉴런 모델이다. 1957년 프랭크 로젠블라트(Frank Rosenblatt)가 제안한 것으로, 오늘날 딥러닝의 출발점이기도 합니다. 퍼셉트론은 단일 "뉴런" 모델로, 실제 인간의 뉴런의 동작 방식에 영감을 받았습니다.
#### 생물학적 뉴런
![퍼셉트론-20251021-1.png](/images/blog/퍼셉트론-20251021-1.png)

다른 뉴런으로 부터 수상 돌기(Dendrites)가 신호를 받아 세포체(Soma)에서 신호를 통합하고 처리합니다. 처리된 신호가 Axon을 지나 다음 뉴런에게 신호를 전달하는 구조이죠.

퍼셉트론은 위 뉴런의 동작 방식에서 크게 벗어나지 않습니다. 데이터(x)를 입력 받아 가중치(w), 가중합(b)을 연산합니다. 이 값을 활성화 함수를 입혀 결과물을 만들어내죠. 퍼셉트론은 다음과 같은 구성요소로 이루어져 있습니다.

![퍼셉트론-20251021-2.png](/images/blog/퍼셉트론-20251021-2.png)

- Inputs : x₁, x₂, x₃, ..., xₙ으로 표현 되는 n개의 입력 신호입니다. 이들은 특징(features) 또는 속성(attributes)을 나타내며, 실수값을 가질 수 있습니다.
- Weights : w₁, w₂, w₃, ..., wₙ으로 표현되며, 각 입력의 중요도를 나타냅니다. 가중치가 크면 해당 입력이 출력에 미치는 영향이 크고, 가중치가 작거나 음수면 영향이 작습니다. 가중치는 학습 과정에서 조정되는 파라미터이고, 딥러닝에서 "학습"의 개념인 데이터입니다.
- bias : b로 표현하며, 활성화 임계값을 조정하는 역할을 합니다. 편향은 입력이 없어도 퍼셉트론이 활성화될 수 있는 기준점을 제공합니다ㅏ. 때로는 가중치가 1인 추가 입력으로 간주되기도 합니다.
- Weighted Sum : 모든 입력과 가중치의 곱의 합에 편향을 더한 값입니다. 
	z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b = Σ(wᵢxᵢ) + b
- Activation Function : 가중합 z를 입력으로 받아 최종 출력을 결정합니다. 단일층 퍼셉트론에서는 계단 함수를 사용합니다.
	φ(z) = 1 (z ≥ 0일 때) 
	φ(z) = 0 (z < 0일 때)

#### 퍼셉트론의 학습 알고리즘
퍼셉트론을 수식으로 표현하면 다음과 같습니다.
y = φ(Σᵢ₌₁ⁿ wᵢxᵢ + b)
입력 벡터와 가중치 벡터의 내적에 활성화 함수를 입히고, 예측값과 정답을 비교하며 가중치 벡터를 수정해 나갑니다.

1단계 : 모든 가중치 w₁, w₂, ..., wₙ과 편향 b를 0 또는 작은 무작위 값으로 설정합니다.
2단계 : 입력 벡터 x와 가중치 백터를 내적합니다.
3단계 : 활성화 함수로 출력 y를 계산합니다.
- y = φ(Σ wᵢxᵢ + b)
4단계 : 예측값 y와 실제 레이블 t를 비교하여 가중치를 업데이트합니다.
- wᵢ_new = wᵢ_old + η × (t - y) × xᵢ 
- b_new = b_old + η × (t - y)
5단계 : 모든 학습 데이터에 대해서 예측이 정확해지거나 미리 정한 반복 횟수(epoch)에 도달할 때까지 2-4단계를 반복합니다.

#### 가중치 업데이트
가중치 업데이트 규칙을 더 쉽게 직관적으로 설명하면 다음과 같습니다. 단일 퍼셉트론이므로, 활성화 함수로 StepFunction을 사용했다고 가정하겠습니다.
- t - y = 0 : 예측이 정확하므로 가중치를 수정하지 않습니다.
- t - y = 1 : 1로 예측해야하는데, 0으로 예측한 케이스입니다. (1 - 0 = 1) 따라서 다음번에는 활성화 되도록 가중치를 증가시킵니다.
- t - y = 0 : 0으로 예측해야하는데, 1로 예측한 케이스입니다. (1 - 1 = 0) 따라서 다음번에는 활성화되지 않도록 조정합니다.

#### 퍼셉트론의 결정 경계
퍼셉트론은 입력 공간을 두개의 영역으로 나누는 선형 결정 경계(linear dicision boundary)를 학습합니다. 2차원 공간에서 이 경계는 직선이고, 3차원 공간에서는 평면이며, n차원 공간에서는 초평면(hyperplane)입니다. 결정 경계는 아래 방정식으로 정의됩니다. 이 경계를 기준으로 클래스가 분류됩니다.
w₁x₁ + w₂x₂ + ... + wₙxₙ + b = 0

![Perceptron-20251023-1.png](/images/blog/Perceptron-20251023-1.png)