---
title: Yolo v1 딥다이브
pubDate: 2025-10-29
description: 욜로 v1 딥다이브
author: KT
tags:
  - Yolo
  - CNN
---
사람은 어떤 물체를 볼때 "저건 강아지다"라고 자동적으로 나오지만, 컴퓨터는 "강아지"라는 것을 인식하기까지 꽤나 복잡한 과정을 거친다. 기존에 학습했던 내용들로 그 과정을 유추해보면, 사진속에 강아지가 잘보이고 꽉 차게 자르고, 사진을 강아지라고 판별하도록 모델을 학습시키면 될 것 같다. 오늘 공부한 YOLO v1은 이 과정을 단 한번에 해결했다. You Only Look Once의 약어로, 한번만 보고 물체를 판별하는 모델이다. 앞서 말한 강아지 사진을 꽉차게 자르고(Localization), 강아지를 판별하게 만드는(Classification) 2가지 네트워크가 필요하게 된다. 이를 "2-stage detector"라고 하는데 YOLO는 이 과정을 한방에 끝내는 "1-stage detector이다." 이렇게 단일 네트워크로 전체 이미지로부터 어떤 물체가 어디있는지 탐지 할 수 있는 이유는 객체 탐지를 공간적으로 분리된 바운딩 박스(bounding box)와 연관된 클래스 확률에 대한 **회귀 문제**로 정의하기 때문입니다.

![Yolo-20251029-1.png](/images/blog/Yolo-20251029-1.png)

먼저 전체 이미지를 SxS(gird)로 나눠줍니다. 물체의 중심이 어떤 그리드 셀에 속하면, 그 그리드 셀은 해당 물체를 탐지할 책임을 집니다. 각 그리드 셀은 