---
title: Word2Vec 논문 내용 정리
pubDate: 2025-11-05
description: Word2Vec 논문 내용 정리
author: KT
tags:
  - Word2Vec
---
## Word2Vec 이전
기존의 NLP 방식에서는 구현이 쉽고 직관적이라는 이유로 단어를 사전 상의 인덱스로 표현했습니다. 
```text
"사과" = 15
"자동차" = 1052
"바나나" = 237
```
해당 방식은 단어 간 의미적 관계를 파악하지는 못하고, 단순히 어휘 사전에서의 구별만 가능했습니다. 하지만, 단순한 기법들의 경우에는 많은 분야에서 한계에 도달했습니다. 예를 들어, 자동 음성 인식에서 음성 데이터 수가 수백만 단어 정도로 제한적입니다. 이는 모델의 성능이 데이터의 크기에 의해 결정되는 것입니다. 더이상 단순히 모델을 발전 시키는 것만으로는 의미가 없어졌고, 다른 부분에 더 집중해야 했습니다. 

기계 학습 기법이 발전하면서 큰 데이터셋에서 복잡한 모델을 학습하는 것이 가능해졌습니다. 2003년 NNLM이 등장하게 됩니다. 이 아키텍처는 입력층, 투영층, 은닉층, 출력층으로 구성되어 있습니다.