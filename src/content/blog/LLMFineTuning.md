---
title: LLM FineTuning
pubDate: 2025-12-02
description: LLM 파인튜닝의 대한 학습
author: KT
tags:
  - LLM
  - FineTuning
  - LoRA
  - QLoRA
---
## 파인튜닝이란?
파인튜닝을 이해하려면, 먼저 LLM이 처음에 어떻게 만들어지는지 이해할 필요가 있다. LLM은 Large Language Model의 약자로 인터넷, 책, 코드, 등 방대한 양의 텍스트 데이터를 모으고 "앞에 단어들이 주어졌을 때, 다음 단어를 예측해봐"라는 문제를 시킨다. 이 행동을 적게는 수십억 많게는 수조번 반복하면서 문법, 상식, 패턴, 등을 자연스럽게 익힌다. 이를 사전학습(Pretraining)이라고 한다. 사전학습은 전체적인 패턴을 이해하지만, 특정 도메인을 학습하지는 않습니다. 특정 회사의 정책이나, 게임 규칙 같이 도메인의 영역으로 들어가면 자세히 알지 못합니다.

파인 튜닝은 이렇게 일반적인 패턴을 학습한 모델을 특정 작업에서 잘하도록 약간의 추가학습을 시키는 것입니다. 즉, 처음부터 다시 학습하는 것이 아니라 이미 학습된 모델(pretrained model)을 가져다가 특정 도메인의 지식을 입히는 과정입니다.

## 파인튜닝의 이점
파인 튜닝의 이점은 크게 4가지가 존재한다.

#### 1. 행동 패턴·말투·성격을 학습시킬 수 있다.
행동패턴·성격·말투는 RAG나 프롬프트로 온전하게 구현이 불가능하다. 반면에 파인 튜닝은 행동 패턴·말투·성격을 모델 가중치로 가져가기 때문에 구현이 가능하다

#### 2. 출력의 일관성 증가
프롬프트 기반으로 출력을 설정하면 상황에 따라 성능이 흔들릴 수 있지만, 파인튜닝은 패턴을 내부적으로 학습하기 때문에 항상 비슷한 스타일·구조로 응답한다.

#### 3. 프롬프트 비용(토큰 비용) 절감
프롬프트로 스타일을 강제시키려고 하면 명령을 구체화 시킬수록 시스템 프롬프트의 토큰이 많아지게 된다. 이는 API 비용의 증가 뿐만 아니라 응답시간도 길어지게 만든다.

#### 4. 생각 구조 학습 가능
프롬프트는 일종의 "지시"이다. 형식을 강용하는 방식인 프롬프트와 다르게 파인튜닝은 모델 내부의 사고 흐름, 논리 구조 자체를 조정한다.

## 파인튜닝의 오해
파인튜닝에 대해 오해할만한 내용들을 정리한다.

#### 1. 파인 튜닝은 새로운 지식을 불어 넣는다.
파인 튜닝은 정확히 말하면 새로운 지식을 불어 넣는다기보다, 특정 도메인에 대한 패턴을 학습시키는 과정이다. 파인 튜닝은 논리 구조, 특정 작업 방식, 말투, 성격 같은 패턴을 학습하는 것이지 새로운 지식들을 활용하고 방대한 문서의 내용을 기억하는 것이 아니다.

#### 2. 파인 튜닝이 RAG보다 좋다.
성능을 올린다든 측면에서 비슷하게 보일 수 있지만, 둘은 아예 목적이 다르다. 파인 튜닝은 앞서 말했듯이 특정 도메인에서의 패턴을 학습한다면, RAG는 사전학습되지 않은 데이터를 활용하여 사실 기반의 정보를 반영시키는 기술이다.

- RAG : 지식의 보충
- FineTuning : 능력의 강화

#### 3. 파인 튜닝은 모델을 기존보다 똑똑하게 만든다.
파인 튜닝은 특정 태스크에서만 능력을 강화하고, 이외의 영역에서는 오히려 성능이 떨어질 수도 있다. 따라서 파인 튜닝은 목적이 명확할 때만 해야한다. 모든걸 파인 튜닝으로 해결하려는 것은 좋지 않다.

## PEFT: Parmeter-Efficient Fine-Tuning
전체 모델을 학습시키지 않고, 필요한 파라미터만 학습해서 훨씬 적은 GPU로, 훨씬 빠르게 파인튜닝하는 기술이다.