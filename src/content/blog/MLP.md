---
title: 다층 퍼셉트론, Multi Layer Perceptron
pubDate: 2025-10-23
description: MLP 기본 개념 정리
author: KT
tags:
  - Perceptron
  - MLP
---
전에 살펴봤던 단일 퍼셉트론은 비선형 문제는 해결할 수 없었습니다. 실제로 단일층 퍼셉트론이 XOR 문제를 해결할 수 없다는 것이 1969년 수학적으로 증명되면서, 다층 구조에 대해 연구가 이루어졌지만 다층 네트워크를 학습시키는 방법이 없었습니다. 1986년 역전파 알고리즘이 널리 보급되면서 은닉층의 가중치를 조정할 수 있게 되었고, MLP가 등장했습니다.

#### MLP의 구조
MLP는 다음과 같은 층들로 구성됩니다. 

###### 1️⃣ 입력층 Input Layer
계산이 수행되지는 않고, 데이터를 받아들이는 역할만 합니다. 뉴런의 개수는 입력 특성(feature)의 개수와 똑같습니다. 28x28 이미지 데이터라면 784개의 입력 뉴런이 존재합니다.

###### 2️⃣ 은닉층, Hidden Layer
입력층과 출력층 사이에 위치한 하나 이상의 층입니다. 각 은닉층은 여러개의 뉴런(노드)으로 구성됩니다. 이 은닉층이 많을 수록 "깊은(deep) 신경망"이라고 합니다. 각 뉴런은 이전 층 그리고 다음층의 모든 뉴런과 연결됩니다. 이를 fully connected라고 표현합니다. 비선형인 활성화 함수를 사용하여 비선형성을 표현합니다.

###### 3️⃣ 출력층, Output Layer
최종 예측 값을 생성하는 Layer입니다. 이진 분류면 2개의 뉴런을 가지고, 다중 클래스 분류면 클래스의 개수만큼 그리고 회귀의 경우에는 예측할 값의 개수만큼 뉴런을 가집니다.