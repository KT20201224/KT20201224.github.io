---
title: 데이터 분할
pubDate: 2024-09-24
description: 데이터 분할의 필요성
author: KT
tags:
  - Data
  - DataSplit
---
#### 데이터 분할? Why?

데이터 분할이란 머신러닝/딥러닝에서 전체 데이터를 용도에 따라 나누는 것을 말합니다. 전체 데이터를 학습용/검증용/테스트용으로 분할하는 것을 의미합니다. 왜 데이터를 분할할까요? 이는 데이터가 한정적이기 때문입니다. 데이터가 끊임 없이 나온다면 우리는 이 고민을 할 필요가 없습니다. 하지만, 데이터는 한정적이고, 때로는 그 양이 많지도 않습니다. 이런 한정된 데이터를 모두 학습할 때 사용한다면, 학습할 때 사용했던 데이터를 테스트에 사용해야 됩니다. 그러면 시험문제를 미리 보고 시험을 푸는 거랑 다를게 없습니다. 테스트의 의미도 없어질 뿐더러, Overfitting이 발생하게 됩니다. 데이터는 크게 3가지(Train, Validation, Test)로 분리합니다.

1. Train Data Set : 모델의 가중치를 학습하는데 사용하는 데이터입니다. 보통 전체 데이터 셋 중 가장 많은 비율(60-80%)을 차지합니다. 
2. Validation Set : 학습 중 모델 성능을 모니터링하고 하이퍼파라미터를 튜닝하는 데 사용합니다. 전체 데이터 셋에서 20-10% 정도의 비율로 설정합니다.
3. Test Set : 최종 시험입니다. 앞선 두 데이터 셋을 바탕으로 학습한 모델이 실제 성능을 평가하기 위한 데이터입니다. 학습이 완전히 끝나고 사용됩니다. 전체 데이터 셋에서 20-10% 정도의 비율로 설정합니다.

#### 데이터 분할 방법
\[방법 1] 수동 분할
```python
from sklearn.model_selection import train_test_split

# 전체 데이터 
X = ... # (10000, 28, 28) 
y = ... # (10000,) 

# 1단계 : Train+Val(80%), Test (20%) 
X_temp, X_test, y_temp, y_test = train_test_split( X, y, test_size=0.2, random_state=42 ) # X_temp: 8000개, X_test: 2000개

# 2단계 : Train(75%), Val(25%)
X_train, X_val, y_train, y_val = train_test_split( X_temp, y_temp, test_size=0.25, random_state=42 ) # X_train: 6000개, X_val: 2000개 
```

`sklearn`의 `train_test_split`을 사용해 수동으로 데이터를 나누는 방법입니다. 위 예시에서 전체 데이터셋에서 Test 20%를 먼저 떼고, 남은 데이터를 Train과 Validation 데이터로 나눕니다.

\[방법 2] `validation_split` 사용

```python
(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# 뒤에 20%를 검증용 데이터로 사용
model.fit(x_train_full, y_train_full, epochs=5, validation_split=0.2)
```

Train, Test 데이터만 있는 상태에서 모델 학습을 할때, 파라미터로 Validation 비율을 넘겨주는 방식입니다. `train_test_split`을 두 번 사용할 필요가 없지만, \[방법 1]과 다르게 순서를 보장하므로, Train 데이터가 정렬된 상태 혹은 데이터가 편향된 경우에는 사용하면 안됩니다. 

#### 분할 비율
데이터 분할에 정답은 없지만, 일반적인 비율은 존재합니다.

| 전체 데이터 크기             | Train  | Validation | Test   |
| --------------------- | ------ | ---------- | ------ |
| 매우 작음 (1,000개 미만)     | 60%    | 20%        | 20%    |
| 작음 (1,000-10,000)     | 70%    | 15%        | 15%    |
| 보통 (10,000-100,000)   | 70-80% | 10-15%     | 10-15% |
| 큼 (100,000-1,000,000) | 80%    | 10%        | 10%    |
| 매우 큼 (1,000,000개 초과)  | 90%    | 5%         | 5%     |
#### 데이터 분할 시 주의사항
1. 데이터 누수(Data Leakage) : 데이터를 정규화 해야 할 경우, 데이터 분할 후에 학습 데이터로만 정규화를 진행해야 한다.
2. 시계열 데이터의 경우에는 랜덤 분할을 금지 한다. 시간 순서를 반드시 유지해줘야 한다. 예를들어 2024년 데이터로 학습하고, 2025년도 데이터로 테스트하는 방식이 올바르다.