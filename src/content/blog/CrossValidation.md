---
title: 교차 검증, Cross Validation (K-Fold CV)
pubDate: 2025-10-23
description: 데이터 교차 검증 학습 내용 정리
author: KT
tags:
  - Data
  - CrossValidation
  - K-FoldCV
---
교차 검증은 머신러닝 모델의 성능을 평가하고 과적합(overfitting)을 방지하기 위한 핵심적인 검증 기법입니다. 단순히 데이터를 Train,Validation,Test로 한번만 나누면 데이터 분할 방식이나 랜덤성에 의하여 성능평가가 크게 달라질 수 있습니다. 예를 들어서 Test 데이터에 너무 쉬운 데이터만 가득하거나 그 반대의 상황이 생기면 모델의 예측 결과가 일반적이지 못하게 됩니다. 또, 한번만 사용하고 버리기엔 제한된 데이터를 최대한 활용하지 못하는 것이기도 합니다.

#### K-Fold CV
K-Fold 교차 검증은 머신러닝에서 가장 널리 사용되는 모델 평가 기법입니다. 데이터를 효율적으로 활용하면서도 신뢰할 수 있는 성능 평가를 제공합니다. K-Fold는 전체 데이터 셋을 K개의 동일한 크기의 부분 집합(Fold)로 나누고, 각 폴드를 순차적으로 검증 세트로 사용하는 방법입니다. K=5인 Fold는 다음과 같이 검증이 진행됩니다.

1단계 : 데이터 분할
- Fold 1 : 샘플 1 ~ 20
- Fold 2 : 샘플 21 ~ 40
- Fold 3 : 샘플 41 ~ 60
- Fold 4 : 샘플 61 ~ 80
- Fold 5 : 샘플 81 ~ 100

2단계 : 반복 학습 후 평가
- 반복 1 : Fold 1을 테스트, Fold 2-5로 훈련 → 정확도 92%
- 반복 2 : Fold 2를 테스트, Fold 1,3-5로 훈련 → 정확도 89%
- 반복 3 : Fold 3을 테스트, Fold 1-2,4-5로 훈련 → 정확도 91%
- 반복 4 : Fold 4를 테스트, Fold 1-3,5로 훈련 → 정확도 90%
- 반복 5 : Fold 5를 테스트, Fold 1-4로 훈련 → 정확도 88%

3단계 : 최종 성능 계산
- 평균 정확도 = 90%
- 표준편차(σ) = 1.58% 

K Fold 에서는 K값에 따라 검증의 장단점이 존재하는데, K값이 작을수록 계산이 빠르지만, 분산이 높아져 평가의 안정성이 떨어집니다. 반면에 K값이 너무 커진다면, 계산 시간이 오래걸리고, 분할 된 데이터 셋의 유사도가 올라가게 됩니다. 따라서 상황에 맞게 적절한 K값을 설정할 필요가 있습니다.

#### 🧠 정리
K-Fold 교차 검증 방식은 모든 데이터가 훈련과 테스트에 사용되어 데이터를 효율적으로 사용하게 되고, 여러번 평가하기 때문에 우연에 의해 결정되는 편향된 결과를 방지합니다. 또, 과적합을 사전에 방지할 수 있습니다.